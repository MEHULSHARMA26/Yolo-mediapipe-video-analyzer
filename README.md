# ğŸ¥ AI Video Analyzer: YOLOv8 + MediaPipe Pose Estimation

A Python project that combines **real-time object detection** using **YOLOv8** and **human pose estimation** using **MediaPipe** to analyze and annotate videos frame-by-frame. The final output is a processed video with both bounding boxes and pose landmarks overlaid.

---

## ğŸ“½ï¸ Demo


> Example:  
> ![demo](assests/cato_pic.png)

---

## ğŸ”§ Features

- âœ… Object detection using **YOLOv8**
- âœ… Human pose estimation using **MediaPipe Pose**
- âœ… Combined overlay on each frame
- âœ… Annotated output video saved locally
- âœ… Clean and modular Python code

---

## ğŸ› ï¸ Technologies Used

- [Python](https://www.python.org/)
- [OpenCV](https://opencv.org/) â€“ for video reading/writing and drawing
- [MediaPipe](https://google.github.io/mediapipe/) â€“ for human pose estimation
- [Ultralytics YOLOv8](https://github.com/ultralytics/ultralytics) â€“ for object detection
- `yolov8n.pt` model â€“ lightweight version for real-time use

---

## ğŸ“ Project Structure
touch_design_proj/
- â”œâ”€â”€ main.py # Main script for video processing
- â”œâ”€â”€ download_model.py # Optional: Preloads the YOLO model
- â”œâ”€â”€ your_video.mp4 # Input video (not uploaded to GitHub)
- â”œâ”€â”€ output_yolo_pose.mp4 # Output video with annotations
- â”œâ”€â”€ requirements.txt # Python dependencies
- â”œâ”€â”€ .gitignore # To exclude venv, videos, cache, etc.
- â””â”€â”€ README.md # This file


---

## ğŸš€ Getting Started

### 1. Clone the repository

```
git clone https://github.com/MEHULSHARMA26/yolo-mediapipe-video-analyzer.git
cd yolo-mediapipe-video-analyzer 
```

### 2. Setting Up Environment
Run in Terminal
```
python -m venv venv
venv\Scripts\activate  ( Windows )
### or
source venv/bin/activate (macOS/Linux)

```

### 3. Install dependencies
```
pip install -r requirements.txt

```
Or manually:
```
pip install opencv-python mediapipe ultralytics

```

### 4. Add input video
Place your video file (.mp4 or .mov) in the project folder and update this line in main.py:

python
```
input_video = r"your_video.mp4"

```
### 5. Run the script
```
python main.py

```

## ğŸ“¦ Output
After processing, the script generates:

ğŸŸ© Bounding boxes from YOLOv8

ğŸ¦´ Skeleton landmarks from MediaPipe Pose

ğŸï¸ Final video saved as output_yolo_pose.mp4
